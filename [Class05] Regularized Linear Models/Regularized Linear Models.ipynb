{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc3b135-3040-4b11-b8d4-dca3ac867e72",
   "metadata": {},
   "source": [
    "# Regularized Linear Models Code Tutorial\n",
    "\n",
    "<b><u>[목적]</u></b>\n",
    "- Regularized Linear Model을 활용하여 Feature selection(Dim reduection)을 진행함\n",
    "- Ridge, Lasso, ElasticNet을 활용함\n",
    "- Hyperparameter를 튜닝할때 for loop 뿐만 아니라 GridsearchCV를 통해 도출할 수 있도록 함\n",
    "\n",
    "<b><u>[Process]</u></b>\n",
    "- Data Path = 'https://github.com/GonieAhn/Data-Science-online-course-from-gonie/tree/main/Data%20Store'\n",
    "- Define X's & Y\n",
    "- Split Train & Valid data set\n",
    "- Modeling (Ridge, Lasso, ElasticNet) & Hyperparameter Tunning\n",
    "- 해석\n",
    "\n",
    "<b><u>[주의]</u></b>\n",
    "- Regularized Linear Models의 경우 X's Scaling을 무조건 진행해야함\n",
    "- Coeff의 Penalty를 변수마다 똑같이 받아야하기 때문 (계수의 Scale을 맞춰야 Penalty를 똑같이 받을 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec0fe44c-63b6-473c-a3dd-d306b3c2c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from regressors import stats\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e4e7b6-855b-4031-954a-ded7eaf53e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Data Shape : (3500, 357)\n",
      "Wall time: 229 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data Load \n",
    "data = pd.read_csv(\"../Data Store/TOY_DATA.csv\")\n",
    "print(\">>>> Data Shape : {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e3f7e-7506-4f28-a57f-5b69e6f8a85e",
   "metadata": {},
   "source": [
    "<b><u>[Data Selection]</u></b>\n",
    "- Data Cleaning 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e8f10b1-e241-43d3-b2b4-62454df148b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape : (3500, 357)\n"
     ]
    }
   ],
   "source": [
    "# Missing value dropping\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(\"Data Shape : {}\".format(data.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7cd4e33-3733-4885-a3ae-a42023501cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain Knowlege를 활용하여 Feature를 선택함\n",
    "sel_col = [\"X23\",\"X22\",\"X21\",\"X254\",\"X247\",\"X246\",\"X245\",\n",
    "           \"X244\",\"X243\",\"X242\",\"X241\",\"X16\",\"X15\",\"X14\",\n",
    "           \"X13\",\"X12\",\"X11\",\"X10\",\"X9\",\"X8\",\"X7\",\"X252\",\n",
    "           \"X251\",\"X250\",\"X249\",\"X248\",\"X20\",\"X19\",\"X253\",\n",
    "           \"X18\",\"X17\",\"X6\",\"X5\",\"X4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "283c9def-b311-4410-a488-4d7f5ed16463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Selection\n",
    "Y = data['Y']\n",
    "X = data[sel_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea4f944-a9fb-488d-9b04-4bea4552fb7c",
   "metadata": {},
   "source": [
    "<b><u>[Data Split]</u></b>\n",
    "- Data Split을 진행할 때 BigData의 경우 꼭 indexing을 추출하여 모델에 적용시켜야 함\n",
    "- 이유는 Data Split하여 새로운 Data set을 만들 경우 메모리에 부담을 주기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f511312c-18ba-456c-828e-de26c2a27106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> # of Train data : 2450\n",
      ">>>> # of valid data : 1050\n"
     ]
    }
   ],
   "source": [
    "idx = list(range(X.shape[0]))\n",
    "train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2021)\n",
    "print(\">>>> # of Train data : {}\".format(len(train_idx)))\n",
    "print(\">>>> # of valid data : {}\".format(len(valid_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b05dde-af46-4eb0-b0a1-64d48fd536d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = MinMaxScaler().fit(X.iloc[train_idx])\n",
    "X_scal = scaler.transform(X)\n",
    "X_scal = pd.DataFrame(X_scal, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b300e1b9-3fb9-4f98-a759-2ee5a2b4651a",
   "metadata": {},
   "source": [
    "<b><u>[Ridge Regression]</u></b>\n",
    "- Hyperparameter Tuning using for Loop\n",
    "- Hyperparameter Tuning using GridSearchCV\n",
    "- 변수 해석 방법은 \"[Class04] Regression Problem Code Tutorial\" 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bee09c0-9139-40b0-99a6-1df81256d27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.00001, R2:0.2161946, MSE:0.0094090, RMSE:0.0970002\n",
      "Alpha:0.00005, R2:0.2161938, MSE:0.0094091, RMSE:0.0970003\n",
      "Alpha:0.00010, R2:0.2161928, MSE:0.0094091, RMSE:0.0970003\n",
      "Alpha:0.00100, R2:0.2161759, MSE:0.0094093, RMSE:0.0970014\n",
      "Alpha:0.01000, R2:0.2160853, MSE:0.0094104, RMSE:0.0970070\n",
      "Alpha:0.10000, R2:0.2163781, MSE:0.0094068, RMSE:0.0969889\n",
      "Alpha:0.30000, R2:0.2174113, MSE:0.0093944, RMSE:0.0969249\n",
      "Alpha:0.50000, R2:0.2180901, MSE:0.0093863, RMSE:0.0968829\n",
      "Alpha:0.60000, R2:0.2182952, MSE:0.0093838, RMSE:0.0968701\n",
      "Alpha:0.70000, R2:0.2184292, MSE:0.0093822, RMSE:0.0968618\n",
      "Alpha:0.90000, R2:0.2185358, MSE:0.0093809, RMSE:0.0968552\n",
      "Alpha:1.00000, R2:0.2185293, MSE:0.0093810, RMSE:0.0968556\n",
      "Alpha:10.00000, R2:0.2082147, MSE:0.0095048, RMSE:0.0974927\n"
     ]
    }
   ],
   "source": [
    "penelty = [0.00001, 0.00005, 0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.6, 0.7, 0.9, 1, 10]\n",
    "\n",
    "# Using For Loop !! \n",
    "# Ridge Regression\n",
    "# select alpha by checking R2, MSE, RMSE\n",
    "for a in penelty:\n",
    "    model = Ridge(alpha=a).fit(X_scal.iloc[train_idx], Y.iloc[train_idx]) #\"normalizse=True\" --> scaling \n",
    "    score = model.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n",
    "    pred_y = model.predict(X_scal.iloc[valid_idx])\n",
    "    mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n",
    "    print(\"Alpha:{0:.5f}, R2:{1:.7f}, MSE:{2:.7f}, RMSE:{3:.7f}\".format(a, score, mse, np.sqrt(mse))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61b2b6bc-7f52-4628-9cbb-013d6cb496a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residuals:\n",
      "    Min      1Q  Median     3Q    Max\n",
      "-0.2148 -0.0572 -0.0078 0.0442 0.6694\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "            Estimate               Std. Error          t value   p value\n",
      "_intercept  0.887908  0.016627+20799.4668470j   0.0000-0.0003j  0.999747\n",
      "X23        -0.259066   0.01300800+0.00000000j -19.9158+0.0000j  0.000000\n",
      "X22        -0.092163   0.02015100+0.00000000j  -4.5737+0.0000j  0.000005\n",
      "X21         0.049482   0.01549500+0.00000000j   3.1934-0.0000j  0.001424\n",
      "X254       -0.018696   0.01569000+0.00000000j  -1.1916+0.0000j  0.233534\n",
      "X247        0.112202   0.02963200+0.00000000j   3.7865-0.0000j  0.000156\n",
      "X246       -0.002081   0.38087500+0.00000000j  -0.0055+0.0000j  0.995640\n",
      "X245       -0.011075   0.01753700+0.00000000j  -0.6315+0.0000j  0.527782\n",
      "X244       -0.010399   0.01451900+0.00000000j  -0.7163+0.0000j  0.473902\n",
      "X243       -0.014547   0.37709100+0.00000000j  -0.0386+0.0000j  0.969231\n",
      "X242       -0.015234   0.02227900+0.00000000j  -0.6838+0.0000j  0.494167\n",
      "X241        0.007162   0.01930700+0.00000000j   0.3709-0.0000j  0.710722\n",
      "X16         0.008478   0.03350400+0.00000000j   0.2530-0.0000j  0.800253\n",
      "X15        -0.011891   0.025119+28616.889252j  -0.0000+0.0000j  1.000000\n",
      "X14         0.025476   0.032729+53213.224150j   0.0000-0.0000j  1.000000\n",
      "X13         0.006684   0.06233700+0.00000000j   0.1072-0.0000j  0.914624\n",
      "X12         0.013000   0.020708+88399.646659j   0.0000-0.0000j  1.000000\n",
      "X11         0.001499   0.03163100+0.00000000j   0.0474-0.0000j  0.962194\n",
      "X10        -0.014592   0.015868+91965.101639j  -0.0000+0.0000j  1.000000\n",
      "X9         -0.009286   0.037912+31549.660264j  -0.0000+0.0000j  1.000000\n",
      "X8         -0.037204   0.06025100+0.00000000j  -0.6175+0.0000j  0.536974\n",
      "X7         -0.014308  0.010059+180251.599298j  -0.0000+0.0000j  1.000000\n",
      "X252        0.015058   0.20428900+0.00000000j   0.0737-0.0000j  0.941246\n",
      "X251       -0.012162   0.07836200+0.00000000j  -0.1552+0.0000j  0.876679\n",
      "X250        0.001899   0.08159300+0.00000000j   0.0233-0.0000j  0.981433\n",
      "X249       -0.020210   0.14085800+0.00000000j  -0.1435+0.0000j  0.885923\n",
      "X248        0.029701   0.04569800+0.00000000j   0.6499-0.0000j  0.515797\n",
      "X20        -0.053981   0.01597900+0.00000000j  -3.3782+0.0000j  0.000741\n",
      "X19         0.160571   0.06953600+0.00000000j   2.3092-0.0000j  0.021017\n",
      "X253       -0.246620   0.07639600+0.00000000j  -3.2282+0.0000j  0.001262\n",
      "X18         0.026861   0.07468000+0.00000000j   0.3597-0.0000j  0.719114\n",
      "X17        -0.027580   0.05538000+0.00000000j  -0.4980+0.0000j  0.618519\n",
      "X6         -0.038933   0.04172600+0.00000000j  -0.9331+0.0000j  0.350882\n",
      "X5          0.030590   0.04330000+0.00000000j   0.7065-0.0000j  0.479967\n",
      "X4          0.012805   0.06714000+0.00000000j   0.1907-0.0000j  0.848758\n",
      "---\n",
      "R-squared:  0.26971,    Adjusted R-squared:  0.25943\n",
      "F-statistic: 26.23 on 34 features\n"
     ]
    }
   ],
   "source": [
    "model_best = Ridge(alpha=0.9).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
    "stats.summary(model_best, X_scal.iloc[train_idx], Y.iloc[train_idx], xlabels = list(X_scal.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3b78700-d05e-4e0f-8397-4b7b0ca87b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha:0.10000, R2:0.2494\n"
     ]
    }
   ],
   "source": [
    "# Using GridSearchCV\n",
    "ridge_cv=RidgeCV(alphas=penelty, cv=5)\n",
    "model = ridge_cv.fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
    "print(\"Best Alpha:{0:.5f}, R2:{1:.4f}\".format(model.alpha_, model.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88abcf8c-39bd-4659-970a-9523741026bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.01000, R2:0.2163781, MSE:0.0094068, RMSE:0.0969889\n",
      "Residuals:\n",
      "    Min      1Q  Median     3Q    Max\n",
      "-0.2162 -0.0569 -0.0077 0.0444 0.6757\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "            Estimate               Std. Error          t value   p value\n",
      "_intercept  0.889774  0.016624+20790.0555420j   0.0000-0.0003j  0.999746\n",
      "X23        -0.264759   0.01304500+0.00000000j -20.2956+0.0000j  0.000000\n",
      "X22        -0.107331   0.02008500+0.00000000j  -5.3439+0.0000j  0.000000\n",
      "X21         0.046228   0.01544900+0.00000000j   2.9924-0.0000j  0.002796\n",
      "X254       -0.030213   0.01564300+0.00000000j  -1.9315+0.0000j  0.053542\n",
      "X247        0.142531   0.02953600+0.00000000j   4.8257-0.0000j  0.000001\n",
      "X246        0.025412   0.37960000+0.00000000j   0.0669-0.0000j  0.946631\n",
      "X245       -0.022026   0.01748500+0.00000000j  -1.2597+0.0000j  0.207885\n",
      "X244       -0.006031   0.01448000+0.00000000j  -0.4165+0.0000j  0.677102\n",
      "X243       -0.046104   0.37582800+0.00000000j  -0.1227+0.0000j  0.902375\n",
      "X242       -0.024549   0.02220600+0.00000000j  -1.1055+0.0000j  0.269052\n",
      "X241        0.009001   0.01924500+0.00000000j   0.4677-0.0000j  0.640048\n",
      "X16         0.016546   0.03339500+0.00000000j   0.4955-0.0000j  0.620319\n",
      "X15        -0.013836   0.025039+28520.684406j  -0.0000+0.0000j  1.000000\n",
      "X14         0.038048   0.032656+53034.330842j   0.0000-0.0000j  0.999999\n",
      "X13        -0.002184   0.06215000+0.00000000j  -0.0351+0.0000j  0.971975\n",
      "X12         0.021648   0.020655+88102.462914j   0.0000-0.0000j  1.000000\n",
      "X11         0.000875   0.03157700+0.00000000j   0.0277-0.0000j  0.977904\n",
      "X10        -0.014222   0.015917+91655.931474j  -0.0000+0.0000j  1.000000\n",
      "X9         -0.000502   0.037823+31443.595969j  -0.0000+0.0000j  1.000000\n",
      "X8         -0.064863   0.06007800+0.00000000j  -1.0796+0.0000j  0.280408\n",
      "X7         -0.010368  0.010103+179645.625774j  -0.0000+0.0000j  1.000000\n",
      "X252        0.086423   0.20360200+0.00000000j   0.4245-0.0000j  0.671260\n",
      "X251       -0.016409   0.07809800+0.00000000j  -0.2101+0.0000j  0.833602\n",
      "X250        0.007556   0.08131900+0.00000000j   0.0929-0.0000j  0.925976\n",
      "X249       -0.078179   0.14038400+0.00000000j  -0.5569+0.0000j  0.577653\n",
      "X248        0.031648   0.04554400+0.00000000j   0.6949-0.0000j  0.487199\n",
      "X20        -0.055547   0.01592700+0.00000000j  -3.4875+0.0000j  0.000496\n",
      "X19         0.386637   0.06930500+0.00000000j   5.5788-0.0000j  0.000000\n",
      "X253       -0.500547   0.07614200+0.00000000j  -6.5739+0.0000j  0.000000\n",
      "X18         0.011999   0.07443000+0.00000000j   0.1612-0.0000j  0.871938\n",
      "X17         0.014012   0.05519500+0.00000000j   0.2539-0.0000j  0.799618\n",
      "X6         -0.043274   0.04159700+0.00000000j  -1.0403+0.0000j  0.298293\n",
      "X5          0.038192   0.04315900+0.00000000j   0.8849-0.0000j  0.376293\n",
      "X4          0.008139   0.06691900+0.00000000j   0.1216-0.0000j  0.903204\n",
      "---\n",
      "R-squared:  0.27461,    Adjusted R-squared:  0.26440\n",
      "F-statistic: 26.89 on 34 features\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV Result\n",
    "model_best = Ridge(alpha=model.alpha_).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
    "score = model_best.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n",
    "pred_y = model_best.predict(X_scal.iloc[valid_idx])\n",
    "mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n",
    "print(\"Alpha:{0:.5f}, R2:{1:.7f}, MSE:{2:.7f}, RMSE:{3:.7f}\".format(0.01, score, mse, np.sqrt(mse)))\n",
    "stats.summary(model_best, X_scal.iloc[train_idx], Y.iloc[train_idx], xlabels=list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cde71d-cbc3-4252-b908-b45b9bd39642",
   "metadata": {},
   "source": [
    "<b><u>[LASSO Regression]</u></b>\n",
    "- Hyperparameter Tuning using for Loop\n",
    "- Hyperparameter Tuning using GridSearchCV\n",
    "- 변수 해석 방법은 \"[Class04] Regression Problem Code Tutorial\" 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9480b954-0c83-4cf8-97f0-0489b0ce1adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.0000001, R2:0.2158, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.0000005, R2:0.2157, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.0000010, R2:0.2156, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.0000050, R2:0.2163, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.0000100, R2:0.2179, MSE:0.0094, RMSE:0.0969\n",
      "Alpha:0.0000500, R2:0.2229, MSE:0.0093, RMSE:0.0966\n",
      "Alpha:0.0001000, R2:0.2189, MSE:0.0094, RMSE:0.0968\n",
      "Alpha:0.0010000, R2:0.1831, MSE:0.0098, RMSE:0.0990\n",
      "Alpha:0.0100000, R2:-0.0004, MSE:0.0120, RMSE:0.1096\n"
     ]
    }
   ],
   "source": [
    "penelty = [0.0000001, 0.0000005, 0.000001, 0.000005,0.00001, 0.00005, 0.0001, 0.001, 0.01]\n",
    "\n",
    "# LASSO Regression\n",
    "# select alpha by checking R2, MSE, RMSE\n",
    "for a in penelty:\n",
    "    model = Lasso(alpha=a).fit(X_scal.iloc[train_idx], Y.iloc[train_idx]) #\"normalizse=True\" --> scaling \n",
    "    score = model.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n",
    "    pred_y = model.predict(X_scal.iloc[valid_idx])\n",
    "    mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n",
    "    print(\"Alpha:{0:.7f}, R2:{1:.4f}, MSE:{2:.4f}, RMSE:{3:.4f}\".format(a, score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6cf2dbd-85da-41bd-b529-0416394b1114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residuals:\n",
      "    Min      1Q  Median     3Q    Max\n",
      "-0.2189 -0.0572 -0.0079 0.0438 0.6743\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "            Estimate               Std. Error          t value   p value\n",
      "_intercept  0.884437  0.016649+20797.3158180j   0.0000-0.0003j  0.999748\n",
      "X23        -0.264110   0.01295500+0.00000000j -20.3869+0.0000j  0.000000\n",
      "X22        -0.098391   0.02010100+0.00000000j  -4.8948+0.0000j  0.000001\n",
      "X21         0.043437   0.01548600+0.00000000j   2.8050-0.0000j  0.005071\n",
      "X254       -0.020798   0.01567700+0.00000000j  -1.3266+0.0000j  0.184750\n",
      "X247        0.102123   0.02960800+0.00000000j   3.4491-0.0000j  0.000572\n",
      "X246       -0.000000   0.38058200+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X245       -0.011616   0.01752700+0.00000000j  -0.6628+0.0000j  0.507553\n",
      "X244       -0.004417   0.01451500+0.00000000j  -0.3043+0.0000j  0.760931\n",
      "X243       -0.003153   0.37680100+0.00000000j  -0.0084+0.0000j  0.993324\n",
      "X242       -0.006729   0.02226300+0.00000000j  -0.3023+0.0000j  0.762481\n",
      "X241        0.000000   0.01929400+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X16        -0.000000   0.03347700+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X15        -0.000000   0.025102+28594.900863j   0.0000+0.0000j  1.000000\n",
      "X14         0.005145   0.032691+53172.336650j   0.0000-0.0000j  1.000000\n",
      "X13         0.000000   0.06227800+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X12         0.000000   0.020685+88331.722932j   0.0000+0.0000j  1.000000\n",
      "X11        -0.012596   0.03163500+0.00000000j  -0.3982+0.0000j  0.690543\n",
      "X10        -0.017224   0.015901+91894.438319j  -0.0000+0.0000j  1.000000\n",
      "X9         -0.000000   0.037872+31525.418419j   0.0000+0.0000j  1.000000\n",
      "X8         -0.012706   0.06018500+0.00000000j  -0.2111+0.0000j  0.832821\n",
      "X7         -0.000000  0.010053+180113.099191j  -0.0000+0.0000j  1.000000\n",
      "X252        0.000000   0.20413200+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X251       -0.000000   0.07830200+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X250        0.000000   0.08153100+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X249       -0.000000   0.14075000+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X248        0.005400   0.04566300+0.00000000j   0.1182-0.0000j  0.905881\n",
      "X20        -0.052737   0.01596800+0.00000000j  -3.3027+0.0000j  0.000971\n",
      "X19         0.242271   0.06948400+0.00000000j   3.4867-0.0000j  0.000498\n",
      "X253       -0.346589   0.07633900+0.00000000j  -4.5401+0.0000j  0.000006\n",
      "X18         0.000000   0.07462300+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X17         0.000000   0.05533800+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X6         -0.010169   0.04169900+0.00000000j  -0.2439+0.0000j  0.807362\n",
      "X5          0.017564   0.04326800+0.00000000j   0.4059-0.0000j  0.684824\n",
      "X4          0.000000   0.06709000+0.00000000j   0.0000+0.0000j  1.000000\n",
      "---\n",
      "R-squared:  0.27083,    Adjusted R-squared:  0.26056\n",
      "F-statistic: 26.38 on 34 features\n"
     ]
    }
   ],
   "source": [
    "model_best = Lasso(alpha=0.00005).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
    "stats.summary(model_best, X_scal.iloc[train_idx], Y.iloc[train_idx], xlabels=list(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c11baca-a830-4b01-b3df-e3603758fe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha : 0.0000500\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation for LASSO\n",
    "lasso_cv=LassoCV(alphas=penelty, cv=5)\n",
    "model = lasso_cv.fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
    "print(\"Best Alpha : {:.7f}\".format(model.alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93fabac6-8648-48cd-96d9-b49d8eb8ba06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.0000500, R2:0.223, MSE:0.0093, RMSE:0.0966\n",
      "Residuals:\n",
      "    Min      1Q  Median     3Q    Max\n",
      "-0.2189 -0.0572 -0.0079 0.0438 0.6743\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "            Estimate               Std. Error          t value   p value\n",
      "_intercept  0.884437  0.016649+20797.3158180j   0.0000-0.0003j  0.999748\n",
      "X23        -0.264110   0.01295500+0.00000000j -20.3869+0.0000j  0.000000\n",
      "X22        -0.098391   0.02010100+0.00000000j  -4.8948+0.0000j  0.000001\n",
      "X21         0.043437   0.01548600+0.00000000j   2.8050-0.0000j  0.005071\n",
      "X254       -0.020798   0.01567700+0.00000000j  -1.3266+0.0000j  0.184750\n",
      "X247        0.102123   0.02960800+0.00000000j   3.4491-0.0000j  0.000572\n",
      "X246       -0.000000   0.38058200+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X245       -0.011616   0.01752700+0.00000000j  -0.6628+0.0000j  0.507553\n",
      "X244       -0.004417   0.01451500+0.00000000j  -0.3043+0.0000j  0.760931\n",
      "X243       -0.003153   0.37680100+0.00000000j  -0.0084+0.0000j  0.993324\n",
      "X242       -0.006729   0.02226300+0.00000000j  -0.3023+0.0000j  0.762481\n",
      "X241        0.000000   0.01929400+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X16        -0.000000   0.03347700+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X15        -0.000000   0.025102+28594.900863j   0.0000+0.0000j  1.000000\n",
      "X14         0.005145   0.032691+53172.336650j   0.0000-0.0000j  1.000000\n",
      "X13         0.000000   0.06227800+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X12         0.000000   0.020685+88331.722932j   0.0000+0.0000j  1.000000\n",
      "X11        -0.012596   0.03163500+0.00000000j  -0.3982+0.0000j  0.690543\n",
      "X10        -0.017224   0.015901+91894.438319j  -0.0000+0.0000j  1.000000\n",
      "X9         -0.000000   0.037872+31525.418419j   0.0000+0.0000j  1.000000\n",
      "X8         -0.012706   0.06018500+0.00000000j  -0.2111+0.0000j  0.832821\n",
      "X7         -0.000000  0.010053+180113.099191j  -0.0000+0.0000j  1.000000\n",
      "X252        0.000000   0.20413200+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X251       -0.000000   0.07830200+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X250        0.000000   0.08153100+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X249       -0.000000   0.14075000+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X248        0.005400   0.04566300+0.00000000j   0.1182-0.0000j  0.905881\n",
      "X20        -0.052737   0.01596800+0.00000000j  -3.3027+0.0000j  0.000971\n",
      "X19         0.242271   0.06948400+0.00000000j   3.4867-0.0000j  0.000498\n",
      "X253       -0.346589   0.07633900+0.00000000j  -4.5401+0.0000j  0.000006\n",
      "X18         0.000000   0.07462300+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X17         0.000000   0.05533800+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X6         -0.010169   0.04169900+0.00000000j  -0.2439+0.0000j  0.807362\n",
      "X5          0.017564   0.04326800+0.00000000j   0.4059-0.0000j  0.684824\n",
      "X4          0.000000   0.06709000+0.00000000j   0.0000+0.0000j  1.000000\n",
      "---\n",
      "R-squared:  0.27083,    Adjusted R-squared:  0.26056\n",
      "F-statistic: 26.38 on 34 features\n"
     ]
    }
   ],
   "source": [
    "model_best = Lasso(alpha=model.alpha_).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
    "score = model_best.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n",
    "pred_y = model_best.predict(X_scal.iloc[valid_idx])\n",
    "mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n",
    "print(\"Alpha:{0:.7f}, R2:{1:.3f}, MSE:{2:.4f}, RMSE:{3:.4f}\".format(model.alpha_, score, mse, np.sqrt(mse)))\n",
    "stats.summary(model_best, X_scal.iloc[train_idx], Y.iloc[train_idx], xlabels=list(X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb971f4-707f-41b0-8ecb-9f05b019c078",
   "metadata": {},
   "source": [
    "<b><u>[ElasticNet]</u></b>\n",
    "- Hyperparameter Tuning using for Loop\n",
    "- Hyperparameter Tuning using GridSearchCV\n",
    "- 변수 해석 방법은 \"[Class04] Regression Problem Code Tutorial\" 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eac607a-d50e-4b47-847c-dd6b045a38d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.00000, Beta: 0.00000, R2:0.215883, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00000, Beta: 0.00001, R2:0.215883, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00000, Beta: 0.00010, R2:0.215883, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00000, Beta: 0.00100, R2:0.215882, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00000, Beta: 0.00500, R2:0.215881, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00000, Beta: 0.01000, R2:0.215879, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00000, Beta: 0.05000, R2:0.215867, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00000, Beta: 0.10000, R2:0.215851, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.00000, R2:0.215912, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.00001, R2:0.215912, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.00010, R2:0.215912, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.00100, R2:0.215911, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.00500, R2:0.215905, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.01000, R2:0.215897, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.05000, R2:0.215835, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.10000, R2:0.215752, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.00000, R2:0.215959, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.00001, R2:0.215959, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.00010, R2:0.215959, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.00100, R2:0.215956, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.00500, R2:0.215944, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.01000, R2:0.215929, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.05000, R2:0.215918, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00001, Beta: 0.10000, R2:0.215992, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00005, Beta: 0.00000, R2:0.216489, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00005, Beta: 0.00001, R2:0.216489, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00005, Beta: 0.00010, R2:0.216490, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00005, Beta: 0.00100, R2:0.216499, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00005, Beta: 0.00500, R2:0.216539, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00005, Beta: 0.01000, R2:0.216588, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00005, Beta: 0.05000, R2:0.217017, MSE:0.0094, RMSE:0.0969\n",
      "Alpha:0.00005, Beta: 0.10000, R2:0.217548, MSE:0.0094, RMSE:0.0969\n",
      "Alpha:0.00010, Beta: 0.00000, R2:0.217154, MSE:0.0094, RMSE:0.0969\n",
      "Alpha:0.00010, Beta: 0.00001, R2:0.217154, MSE:0.0094, RMSE:0.0969\n",
      "Alpha:0.00010, Beta: 0.00010, R2:0.217158, MSE:0.0094, RMSE:0.0969\n",
      "Alpha:0.00010, Beta: 0.00100, R2:0.217189, MSE:0.0094, RMSE:0.0969\n",
      "Alpha:0.00010, Beta: 0.00500, R2:0.217330, MSE:0.0094, RMSE:0.0969\n",
      "Alpha:0.00010, Beta: 0.01000, R2:0.217502, MSE:0.0094, RMSE:0.0969\n",
      "Alpha:0.00010, Beta: 0.05000, R2:0.218501, MSE:0.0094, RMSE:0.0969\n",
      "Alpha:0.00010, Beta: 0.10000, R2:0.219599, MSE:0.0094, RMSE:0.0968\n",
      "Alpha:0.00100, Beta: 0.00000, R2:0.216933, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00100, Beta: 0.00001, R2:0.216933, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00100, Beta: 0.00010, R2:0.216934, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00100, Beta: 0.00100, R2:0.216941, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00100, Beta: 0.00500, R2:0.216974, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00100, Beta: 0.01000, R2:0.217034, MSE:0.0094, RMSE:0.0969\n",
      "Alpha:0.00100, Beta: 0.05000, R2:0.216843, MSE:0.0094, RMSE:0.0970\n",
      "Alpha:0.00100, Beta: 0.10000, R2:0.214514, MSE:0.0094, RMSE:0.0971\n",
      "Alpha:0.00500, Beta: 0.00000, R2:0.206153, MSE:0.0095, RMSE:0.0976\n",
      "Alpha:0.00500, Beta: 0.00001, R2:0.206152, MSE:0.0095, RMSE:0.0976\n",
      "Alpha:0.00500, Beta: 0.00010, R2:0.206147, MSE:0.0095, RMSE:0.0976\n",
      "Alpha:0.00500, Beta: 0.00100, R2:0.206094, MSE:0.0095, RMSE:0.0976\n",
      "Alpha:0.00500, Beta: 0.00500, R2:0.205725, MSE:0.0095, RMSE:0.0976\n",
      "Alpha:0.00500, Beta: 0.01000, R2:0.205153, MSE:0.0095, RMSE:0.0977\n",
      "Alpha:0.00500, Beta: 0.05000, R2:0.195639, MSE:0.0097, RMSE:0.0983\n",
      "Alpha:0.00500, Beta: 0.10000, R2:0.189724, MSE:0.0097, RMSE:0.0986\n",
      "Alpha:0.01000, Beta: 0.00000, R2:0.196843, MSE:0.0096, RMSE:0.0982\n",
      "Alpha:0.01000, Beta: 0.00001, R2:0.196843, MSE:0.0096, RMSE:0.0982\n",
      "Alpha:0.01000, Beta: 0.00010, R2:0.196844, MSE:0.0096, RMSE:0.0982\n",
      "Alpha:0.01000, Beta: 0.00100, R2:0.196832, MSE:0.0096, RMSE:0.0982\n",
      "Alpha:0.01000, Beta: 0.00500, R2:0.196641, MSE:0.0096, RMSE:0.0982\n",
      "Alpha:0.01000, Beta: 0.01000, R2:0.195771, MSE:0.0097, RMSE:0.0983\n",
      "Alpha:0.01000, Beta: 0.05000, R2:0.185408, MSE:0.0098, RMSE:0.0989\n",
      "Alpha:0.01000, Beta: 0.10000, R2:0.177967, MSE:0.0099, RMSE:0.0993\n",
      "Alpha:0.05000, Beta: 0.00000, R2:0.148990, MSE:0.0102, RMSE:0.1011\n",
      "Alpha:0.05000, Beta: 0.00001, R2:0.148986, MSE:0.0102, RMSE:0.1011\n",
      "Alpha:0.05000, Beta: 0.00010, R2:0.148898, MSE:0.0102, RMSE:0.1011\n",
      "Alpha:0.05000, Beta: 0.00100, R2:0.148056, MSE:0.0102, RMSE:0.1011\n",
      "Alpha:0.05000, Beta: 0.00500, R2:0.143674, MSE:0.0103, RMSE:0.1014\n",
      "Alpha:0.05000, Beta: 0.01000, R2:0.138918, MSE:0.0103, RMSE:0.1017\n",
      "Alpha:0.05000, Beta: 0.05000, R2:0.108301, MSE:0.0107, RMSE:0.1035\n",
      "Alpha:0.05000, Beta: 0.10000, R2:0.076192, MSE:0.0111, RMSE:0.1053\n"
     ]
    }
   ],
   "source": [
    "# alphas range (0 ~ 1), alpha = 0 is equivalent to an ordinary least square, solved by the LinearRegression object.\n",
    "alphas = [0.000001, 0.000005, 0.00001, 0.00005, 0.0001, 0.001, 0.005, 0.01, 0.05]\n",
    "# betas range (0 ~ 1), l1_ratio is often to put more values close to 1 (i.e. Lasso) and less close to 0 (i.e. Ridge)\n",
    "betas = [0.000001, 0.000005, 0.0001, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# ElasticNet Regression\n",
    "# select alpha and beta by checking R2, MSE, RMSE\n",
    "for a in alphas:\n",
    "    for b in betas:\n",
    "        model = ElasticNet(alpha=a, l1_ratio=b).fit(X_scal.iloc[train_idx], Y.iloc[train_idx]) #\"normalizse=True\" --> scaling \n",
    "        score = model.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n",
    "        pred_y = model.predict(X_scal.iloc[valid_idx])\n",
    "        mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n",
    "        print(\"Alpha:{0:.5f}, Beta: {1:.5f}, R2:{2:.6f}, MSE:{3:.4f}, RMSE:{4:.4f}\".format(a, b, score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91d68514-ef3d-4568-b78e-79375e8a6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation for ElasticNet\n",
    "grid = dict()\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b436c82e-de9b-4bf4-89e9-7ea127cf5c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0968\n",
      "Config: {'alpha': 0.001, 'l1_ratio': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = ElasticNet()\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring='neg_root_mean_squared_error', cv=5, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search.fit(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n",
    "# summarize\n",
    "print('RMSE: {:.4f}'.format(-results.best_score_))\n",
    "print('Config: {}'.format(results.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0705c21-b435-4d48-806e-71eff2faf264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.00100, Beta: 0.10000, R2:0.214514, MSE:0.0094, RMSE:0.0971\n",
      "Residuals:\n",
      "   Min      1Q  Median     3Q    Max\n",
      "-0.218 -0.0576 -0.0073 0.0438 0.6678\n",
      "\n",
      "\n",
      "Coefficients:\n",
      "            Estimate               Std. Error          t value   p value\n",
      "_intercept  0.868238  0.016688+20820.7268440j   0.0000-0.0003j  0.999754\n",
      "X23        -0.241872   0.01300400+0.00000000j -18.5997+0.0000j  0.000000\n",
      "X22        -0.060408   0.02028400+0.00000000j  -2.9781+0.0000j  0.002928\n",
      "X21         0.037315   0.01560700+0.00000000j   2.3909-0.0000j  0.016880\n",
      "X254       -0.002670   0.01580300+0.00000000j  -0.1690+0.0000j  0.865829\n",
      "X247        0.063328   0.02985600+0.00000000j   2.1211-0.0000j  0.034014\n",
      "X246        0.000000   0.38376500+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X245       -0.000000   0.01766400+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X244       -0.015758   0.01461900+0.00000000j  -1.0779+0.0000j  0.281179\n",
      "X243        0.000000   0.37995200+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X242       -0.000000   0.02244600+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X241       -0.000000   0.01945100+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X16        -0.000000   0.03375500+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X15        -0.000626   0.025309+28834.214554j  -0.0000+0.0000j  1.000000\n",
      "X14         0.000000   0.032991+53617.341450j   0.0000+0.0000j  1.000000\n",
      "X13         0.000000   0.06282400+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X12        -0.000000   0.020876+89070.980280j   0.0000+0.0000j  1.000000\n",
      "X11        -0.005212   0.03190100+0.00000000j  -0.1634+0.0000j  0.870230\n",
      "X10        -0.015790   0.016052+92663.512402j  -0.0000+0.0000j  1.000000\n",
      "X9         -0.000000   0.038232+31789.257915j   0.0000+0.0000j  1.000000\n",
      "X8         -0.000000   0.06071600+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X7         -0.007342  0.010170+181620.484395j  -0.0000+0.0000j  1.000000\n",
      "X252        0.000000   0.20584000+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X251        0.000000   0.07895700+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X250        0.000000   0.08221300+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X249        0.000000   0.14192800+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X248        0.000000   0.04604500+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X20        -0.050025   0.01609900+0.00000000j  -3.1073+0.0000j  0.001910\n",
      "X19         0.000000   0.07006100+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X253       -0.052585   0.07697400+0.00000000j  -0.6831+0.0000j  0.494579\n",
      "X18        -0.000000   0.07524600+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X17        -0.012638   0.05579900+0.00000000j  -0.2265+0.0000j  0.820835\n",
      "X6         -0.000000   0.04202900+0.00000000j   0.0000+0.0000j  1.000000\n",
      "X5          0.007683   0.04362200+0.00000000j   0.1761-0.0000j  0.860218\n",
      "X4          0.000000   0.06764300+0.00000000j   0.0000+0.0000j  1.000000\n",
      "---\n",
      "R-squared:  0.25857,    Adjusted R-squared:  0.24814\n",
      "F-statistic: 24.77 on 34 features\n"
     ]
    }
   ],
   "source": [
    "model_best = ElasticNet(alpha=results.best_params_['alpha'], \n",
    "                        l1_ratio=results.best_params_['l1_ratio']).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
    "score = model_best.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n",
    "pred_y = model_best.predict(X_scal.iloc[valid_idx])\n",
    "mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n",
    "print(\"Alpha:{0:.5f}, Beta: {1:.5f}, R2:{2:.6f}, MSE:{3:.4f}, RMSE:{4:.4f}\".format(results.best_params_['alpha'], \n",
    "                                                                                   results.best_params_['l1_ratio'], \n",
    "                                                                                   score, mse, np.sqrt(mse)))\n",
    "stats.summary(model_best, X_scal.iloc[train_idx], Y.iloc[train_idx], xlabels=list(X.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
